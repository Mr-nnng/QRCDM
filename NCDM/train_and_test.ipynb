{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Cognitive Diagnosis Model (NCDM)\n",
    "This notebook will show you how to train and use the NCDM. First, we will show how to get the data (here we use a0910 as the dataset). Then we will show how to train a NCDM and perform the parameters persistence. At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [NCDM.py](NCDM.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Before we process the data, we need to first acquire the dataset which is shown in this [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集： FrcSub\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score\n",
       "0        1        1    0.0\n",
       "1        1        3    0.0\n",
       "2        1        5    0.0\n",
       "3        1        6    0.0\n",
       "4        1        7    1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataSet_list = ('FrcSub','Math1', 'Math2','ASSIST_0910', 'ASSIST_2017')\n",
    "dataSet = dataSet_list[0]\n",
    "\n",
    "if dataSet == 'ASSIST_0910':\n",
    "    read_dir = '../data/a0910/'\n",
    "    sub_prob_index=[]\n",
    "    valid_data = pd.read_csv(read_dir+\"valid.csv\")\n",
    "elif dataSet == 'ASSIST_2017':\n",
    "    read_dir = '../data/a2017/'\n",
    "    sub_prob_index=[]\n",
    "    valid_data = pd.read_csv(read_dir+\"valid.csv\")\n",
    "elif dataSet == 'FrcSub':\n",
    "    read_dir='../data/frcSub/'\n",
    "    sub_prob_index=[]\n",
    "    valid_data = pd.read_csv(read_dir+\"test.csv\")\n",
    "elif dataSet == 'Math1':\n",
    "    read_dir='../data/math1/'\n",
    "    sub_prob_index=np.loadtxt(read_dir+'sub_prob_index.csv',dtype=int)\n",
    "    valid_data = pd.read_csv(read_dir+\"test.csv\")\n",
    "elif dataSet == 'Math2':\n",
    "    read_dir='../data/math2/'\n",
    "    sub_prob_index=np.loadtxt(read_dir+'sub_prob_index.csv',dtype=int)\n",
    "    valid_data = pd.read_csv(read_dir+\"test.csv\")\n",
    "else:\n",
    "    print('Dataset does not exist!')\n",
    "    exit(0)\n",
    "print('数据集：', dataSet)\n",
    "\n",
    "train_data = pd.read_csv(read_dir+\"train.csv\")\n",
    "\n",
    "test_data = pd.read_csv(read_dir+\"test.csv\")\n",
    "df_item = pd.read_csv(read_dir+\"item.csv\")\n",
    "\n",
    "item2knowledge = {}\n",
    "knowledge_set = set()\n",
    "for i, s in df_item.iterrows():\n",
    "    item_id, knowledge_codes = s['item_id'], list(set(eval(s['knowledge_code'])))\n",
    "    item2knowledge[item_id] = knowledge_codes\n",
    "    knowledge_set.update(knowledge_codes)\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>knowledge_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 4, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[2, 5, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[2, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[2, 4, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[2, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[1, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[2, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[2, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[2, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[1, 2, 3, 5, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[2, 3, 5, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id   knowledge_code\n",
       "0         1        [4, 6, 7]\n",
       "1         2           [4, 7]\n",
       "2         3           [4, 7]\n",
       "3         4     [2, 3, 5, 7]\n",
       "4         5     [2, 4, 7, 8]\n",
       "5         6              [7]\n",
       "6         7        [1, 2, 7]\n",
       "7         8              [7]\n",
       "8         9              [2]\n",
       "9        10     [2, 5, 7, 8]\n",
       "10       11        [2, 5, 7]\n",
       "11       12           [7, 8]\n",
       "12       13     [2, 4, 5, 7]\n",
       "13       14           [2, 7]\n",
       "14       15           [1, 7]\n",
       "15       16           [2, 7]\n",
       "16       17        [2, 5, 7]\n",
       "17       18     [2, 5, 6, 7]\n",
       "18       19  [1, 2, 3, 5, 7]\n",
       "19       20     [2, 3, 5, 7]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 2144, 2144)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 20, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get basic data info for model initialization\n",
    "import numpy as np\n",
    "user_n = np.max(train_data['user_id'])\n",
    "item_n = np.max([np.max(train_data['item_id']), np.max(valid_data['item_id']), np.max(test_data['item_id'])])\n",
    "knowledge_n = np.max(list(knowledge_set))\n",
    "\n",
    "user_n, item_n, knowledge_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x22278c8f130>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x22210557a30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x22210557f10>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to torch Dataloader (i.e., batchify)\n",
    "# batch_size is set to 32\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "def transform(user, item, item2knowledge, score, batch_size):\n",
    "    knowledge_emb = torch.zeros((len(item), knowledge_n))\n",
    "    for idx in range(len(item)):\n",
    "        knowledge_emb[idx][np.array(item2knowledge[item[idx]]) - 1] = 1.0\n",
    "\n",
    "    data_set = TensorDataset(\n",
    "        torch.tensor(user, dtype=torch.int64) - 1,  # (1, user_n) to (0, user_n-1)\n",
    "        torch.tensor(item, dtype=torch.int64) - 1,  # (1, item_n) to (0, item_n-1)\n",
    "        knowledge_emb,\n",
    "        torch.tensor(score, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_set, valid_set, test_set = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], item2knowledge, data[\"score\"], batch_size)\n",
    "    for data in [train_data, valid_data, test_data]\n",
    "]\n",
    "\n",
    "train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 268/268 [00:00<00:00, 360.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] average loss: 0.955596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 67/67 [00:00<00:00, 1049.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] obj_acc: 0.534049,obj_auc: 0.611185,obj_rmse: 0.499534, obj_mae: 0.495882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 268/268 [00:00<00:00, 375.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] average loss: 0.693264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 67/67 [00:00<00:00, 781.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] obj_acc: 0.465951,obj_auc: 0.661415,obj_rmse: 0.500797, obj_mae: 0.500694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 268/268 [00:00<00:00, 352.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] average loss: 0.693863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 67/67 [00:00<00:00, 855.70it/s]\n",
      "INFO:root:save parameters to ncdm.snapshot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] obj_acc: 0.534049,obj_auc: 0.741887,obj_rmse: 0.499447, obj_mae: 0.495899\n"
     ]
    }
   ],
   "source": [
    "from NCDM import NCDM\n",
    "\n",
    "cdm = NCDM(knowledge_n, item_n, user_n)\n",
    "cdm.train(train_set, valid_set, sub_prob_index ,epoch=3, device=\"cuda\")\n",
    "cdm.save(\"ncdm.snapshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from ncdm.snapshot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_set_name: FrcSub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 67/67 [00:00<00:00, 946.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_acc: 0.534049,obj_auc: 0.741899,obj_rmse: 0.499447, obj_mae: 0.495899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"ncdm.snapshot\")\n",
    "print('data_set_name:',dataSet)\n",
    "if len(sub_prob_index)>0:\n",
    "    (obj_acc,obj_auc,obj_rmse,obj_mae),(sub_rmse,sub_mae) = cdm.eval(test_set,sub_prob_index)\n",
    "    print(\"obj_acc: %.6f,obj_auc: %.6f,obj_rmse: %.6f, obj_mae: %.6f,\\nsub_rmse: %.6f, sub_mae: %.6f\"% (\n",
    "        obj_acc,obj_auc,obj_rmse,obj_mae,sub_rmse,sub_mae))\n",
    "else:\n",
    "    obj_acc,obj_auc,obj_rmse,obj_mae = cdm.eval(test_set,sub_prob_index)\n",
    "    print(\"obj_acc: %.6f,obj_auc: %.6f,obj_rmse: %.6f, obj_mae: %.6f\" % (\n",
    "        obj_acc,obj_auc,obj_rmse,obj_mae))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "527a93331b4b1a8345148922acc34427fb7591433d63b66d32040b6fbbc6d593"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
